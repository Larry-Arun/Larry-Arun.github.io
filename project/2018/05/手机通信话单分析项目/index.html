<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<title>Spark Streaming实时流处理日志项目</title>
<meta name="description" content="一个Flex布局的实例 - Mia Wang">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="short icon" href="/favicon.png">
<link rel="stylesheet" href="/css/apollo.css">
<link rel="stylesheet"
	href="http://fonts.useso.com/css?family=Source+Sans+Pro:400,600"
	type="text/css">
</head>
<body>
	<div class="wrap">
		<header>
			<a href="/" class="logo-link"><img src="/favicon.png"></a>
			<ul class="nav nav-list">
				<li class="nav-list-item"><a href="/" target="_self"
					class="nav-list-link active">PROJECT</a></li>
				<li class="nav-list-item"><a href="/archives/" target="_self"
					class="nav-list-link">SKILL</a></li>
				<li class="nav-list-item"><a
					href="https://github.com/Larry-Arun" target="_blank"
					class="nav-list-link">GITHUB</a></li>
				<li class="nav-list-item"><a
					href="https://Larry-Arun.github.io/resume/" target="_blank"
					class="nav-list-link">RESUME</a></li>
				<li class="nav-list-item"><a
					href="https://Larry-Arun.github.io/Tank-World-War" target="_blank"
					class="nav-list-link"></a></li>
			</ul>
		</header>
		<section class="container">
			<div class="post">
				<article class="post-block">
					<h1 class="post-title">Spark Streaming实时流处理日志项目</h1>
					<p>May 18, 2018</p>
					<div class="post-content">
						<a id="more"></a>
						<h3 id="1-属性简介">
							<a href="#1-属性简介" class="headerlink" title="1.属性简介"></a>开发环境
						</h3>
						<p>IDEA+maven+JDK+linux</p>
						<h3 id="1-属性简介">
							<a href="#1-属性简介" class="headerlink" title="1.属性简介"></a>系统架构
						</h3>
						<p>hadoop+zookeeper+flume+ kafka+ spark+hbase</p>
						<h3 id="1-属性简介">
							<a href="#1-属性简介" class="headerlink" title="1.属性简介"></a>需求描述
						</h3>
						<p>实时（到现在为止）的日志访问统计操作</p>
						<h3 id="2-一个实例">
							<a href="#2-一个实例" class="headerlink" title="2.一个实例"></a>项目描述
						</h3>
						<p>项目数据来源的日志为Python脚本产生的，通过crontab定时执行Python脚本模仿服务器日志的产生，
							日志包括ip、time、url、status、referer。然后使用flume采集产生的日志数据
							并sink到Kafka消息队列中，然后将日志信息传给Spark Streaming进行实时数据处理。
							最后将计算结果写入到Hbase上。</p>
						<h3 id="2-一个实例">
							<a href="#2-一个实例" class="headerlink" title="2.一个实例"></a>项目步骤
						</h3>
						<ul>
							<li>通过Python脚本模仿日志的产生；</li>
							<li>Flume的选型，在本例中设为exec-memory-kafka；</li>
							<li>打开kafka一个消费者，再启动flume读取日志生成器中的log文件，可看到
								kafka中成功读取到日志产生器的实时数据 ；</li>
							<li>让Kafka接收到的数据传输到Spark Streaming当中，这样就可以在Spark对
								实时接收到的数据进行操作了 ；</li>
							<li>Spark中对实时数据的操作分为数据清洗过程、统计功能实现过程两个步骤。 其中统计功能的实现基本上和Spark
								SQL中的操作一致，体现了Spark的代码复 用性，即能通用于多个框架中 ；</li>
							<li>计算结果写入到Hbase。</li>
						</ul>
						<h3 id="3">
							<a
								href="https://github.com/Larry-Arun/Spark-Streaming/tree/master/sparktrain/src/main/scala/com/imooc/spark/project"
								class="headerlink" target="_blank">项目源码</a>
						</h3>
					</div>
				</article>
			</div>
		</section>
		<footer>
			<div class="paginator">
				<a href="/project/2018/02/某视频网站运营指标分析项目/" class="next">NEXT</a>
				<div class="copyright">
					<p>
						© 2018 - project <a href="https://Larry-Arun.github.io/resume/"
							target="_blank">My Resume</a>
					</p>
				</div>
			</div>
		</footer>
		<script async
			src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
		<script>
			(function(b, o, i, l, e, r) {
				b.GoogleAnalyticsObject = l;
				b[l] || (b[l] = function() {
					(b[l].q = b[l].q || []).push(arguments)
				});
				b[l].l = +new Date;
				e = o.createElement(i);
				r = o.getElementsByTagName(i)[0];
				e.src = '//www.google-analytics.com/analytics.js';
				r.parentNode.insertBefore(e, r)
			}(window, document, 'script', 'ga'));
			ga('create', "UA-65933410-1", 'auto');
			ga('send', 'pageview');
		</script>
	</div>
</body>
</html>